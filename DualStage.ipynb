{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac089889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model, Input, layers, models, Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from PIL import UnidentifiedImageError, ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fb338",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = 'model/model_final.keras'\n",
    "decoder_path = 'model/decoder.keras'\n",
    "DATA_DIR = \"Ground Truth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a79ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_encoder_decoder(encoder_path, decoder_path):\n",
    "    encoder = load_model(encoder_path)\n",
    "    decoder = load_model(decoder_path)\n",
    "\n",
    "    input_shape = encoder.input_shape[1:]\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    latent_output = encoder(inputs)\n",
    "\n",
    "    decoded_output = decoder(latent_output)\n",
    "    \n",
    "    full_model = Model(inputs=inputs, outputs=decoded_output, name=\"DualStageNetwork\")\n",
    "\n",
    "    full_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    # drive.mount('/content/drive')\n",
    "\n",
    "    all_imgs = sorted(\n",
    "        [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))],\n",
    "        key=lambda x: int(''.join(filter(str.isdigit, os.path.basename(x))))\n",
    "    )\n",
    "\n",
    "    # train_files, test_files = train_test_split(all_imgs, test_size=0.3, random_state=42)\n",
    "    # val_files, test_files   = train_test_split(test_files, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_files = all_imgs[:500]\n",
    "    val_files   = all_imgs[500:608]\n",
    "    test_files  = all_imgs[608:]\n",
    "\n",
    "    print(f\"Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")\n",
    "    return train_files, val_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7786fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file_list):\n",
    "    data = []\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            img = load_img(f, target_size=(128, 128), color_mode=\"rgb\")\n",
    "            arr = img_to_array(img) / 255.0\n",
    "            data.append(arr)\n",
    "        except (OSError, UnidentifiedImageError) as e:\n",
    "            print(f\"⚠️ Skipping corrupted image: {f} ({e})\")\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, X_input, Y_target, n=5):\n",
    "    preds = model.predict(X_input[:n])\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i in range(n):\n",
    "        # Input\n",
    "        plt.subplot(n, 3, 3*i + 1)\n",
    "        inp = X_input[i]\n",
    "        if inp.shape[-1] == 2:\n",
    "            inp = inp[..., :1]        # atau buat heatmap grayscale\n",
    "        plt.imshow(np.clip(inp, 0, 1), cmap=\"gray\")\n",
    "        plt.title(\"Input\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Target\n",
    "        plt.subplot(n, 3, 3*i + 2)\n",
    "        plt.imshow(np.clip(Y_target[i], 0, 1))\n",
    "        plt.title(\"Target\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Output\n",
    "        plt.subplot(n, 3, 3*i + 3)\n",
    "        plt.imshow(np.clip(preds[i], 0, 1))\n",
    "        plt.title(\"Output\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape, latent_dim):\n",
    "  model = Sequential([\n",
    "      Input(shape=input_shape),\n",
    "      layers.Conv2D(16, (3,3), activation='relu', strides=1),\n",
    "      layers.MaxPooling2D((2,2)),\n",
    "      layers.Conv2D(32, (3,3), activation='relu', strides=1),\n",
    "      layers.MaxPooling2D((2,2)),\n",
    "      layers.Conv2D(64, (3,3), activation='relu', strides=1),\n",
    "      layers.MaxPooling2D((2,2)),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "      layers.Dense(latent_dim, activation='linear')\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(img_size, latent_dim):\n",
    "  inputs = layers.Input(shape=(latent_dim,))\n",
    "\n",
    "  x = layers.Dense((img_size//8) * (img_size//8) * 64, activation=\"relu\")(inputs)\n",
    "  x = layers.Reshape((img_size//8, img_size//8, 64))(x)\n",
    "\n",
    "  x = layers.Conv2DTranspose(64, (3,3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "  x = layers.Conv2DTranspose(32, (3,3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "  x = layers.Conv2DTranspose(16, (3,3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "  outputs = layers.Conv2DTranspose(3, (3,3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "  return models.Model(inputs, outputs, name=\"Decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf18879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_loss(y_true, y_pred):\n",
    "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    ssim = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    return 0.8 * mae + 0.2 * ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_signal = np.load(\"latent_rep/final_dataset_baru.npy\")\n",
    "\n",
    "train_files, test_files, val_files = load_data(DATA_DIR)\n",
    "train_data = load_images(train_files)\n",
    "val_data   = load_images(val_files)\n",
    "test_data  = load_images(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd83476",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_cnn(input_shape=(24,24,2), latent_dim=256)\n",
    "decoder = build_decoder(img_size=128, latent_dim=256)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(24,24,2))\n",
    "latent = encoder(inputs)\n",
    "outputs = decoder(latent)\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs, outputs)\n",
    "autoencoder.compile(optimizer='adam', loss=ae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ffc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_signal[:500], train_data, epochs=30, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb673c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model = combine_encoder_decoder(encoder_path, decoder_path)\n",
    "# full_model.summary()\n",
    "# full_model.fit(X_signal[:500], train_data, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(full_model, X_signal, train_data, n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec363aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
